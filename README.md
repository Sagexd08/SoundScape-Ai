# üéµ SoundScape AI

> AI-powered audio environments that adapt to your surroundings and mood in real-time.

<div align="center">
  <img src="https://res.cloudinary.com/dm9h4bawl/image/upload/v1745427929/Screenshot_2025-04-23_223435_ahljcf.png" alt="SoundScape AI Logo" width="150"/>
  
  ![Build Status](https://img.shields.io/badge/build-passing-brightgreen) 
  ![License](https://img.shields.io/badge/license-MIT-blue) 
  ![AI Models](https://img.shields.io/badge/AI%20Models-3-purple)
  ![Vercel](https://img.shields.io/badge/Vercel-Deployed-black)
</div>

---

## üìå Problem Statement

**Problem Statement 12 ‚Äì Revolutionize Audio Experiences with AI**

Create innovative solutions that transform how we interact with and experience audio content through artificial intelligence.

---

## üéØ Objective

SoundScape AI solves the problem of generic, static audio environments by creating personalized, adaptive soundscapes that respond to users' surroundings, activities, and emotional states in real-time.

Our platform serves content creators, meditation practitioners, productivity enthusiasts, and anyone seeking immersive audio experiences. By combining multiple AI models (OpenAI, Grok, and Gemini), we deliver unparalleled audio environments that enhance focus, relaxation, creativity, and overall well-being.

---

## üß† Team & Approach

### Team Name:  
`SoundWave Innovators`

### Team Members:  
- Sohom Chatterjee ([GitHub](https://github.com/Sagexd08) / Lead Developer)  
- Aryan Sharma (UI/UX Designer)  
- Priya Patel (AI Integration Specialist)  
- Rahul Mehta (Backend Developer)  

### Our Approach:  
- We chose this problem because audio experiences remain largely static despite advances in AI, presenting an opportunity to create truly adaptive environments.
- Key challenges we addressed include integrating multiple AI models for enhanced creativity, implementing real-time adaptation to user context, and creating an intuitive interface for audio customization.
- Our breakthrough came when we developed a collaborative AI approach that combines the strengths of different models (Grok for detailed prompts, Gemini for creative enhancement, and OpenAI for high-quality synthesis).

---

## üõ†Ô∏è Tech Stack

### Core Technologies Used:
- **Frontend:** Next.js 14, React, TypeScript, Tailwind CSS, Framer Motion
- **Backend:** Supabase for authentication and database
- **Database:** Supabase PostgreSQL
- **AI:** OpenAI API, Grok API, Gemini API
- **Hosting:** Vercel
- **Authentication:** Supabase Auth with Google OAuth
- **UI Components:** shadcn/ui
- **3D Graphics:** Three.js

### Sponsor Technologies Used:
- [‚úÖ] **Groq:** Used for ultra-fast audio prompt generation and analysis
- [ ] **Monad:** _Not implemented in current version_
- [ ] **Fluvio:** _Not implemented in current version_
- [ ] **Base:** _Not implemented in current version_
- [ ] **Screenpipe:** _Not implemented in current version_
- [ ] **Stellar:** _Not implemented in current version_

---

## ‚ú® Key Features

<div align="center">
  <img src="https://res.cloudinary.com/dporz9gz6/image/upload/v1745176839/WhatsApp_Image_2025-04-21_at_00.38.35_372fbb13_iuvgdy.jpg" alt="SoundScape Features" width="600"/>
</div>

- ‚úÖ **Multi-AI Collaboration:** Unique integration of Grok, Gemini, and OpenAI for superior audio generation
- ‚úÖ **Environment-Based Audio:** Generate soundscapes based on different environments (forest, ocean, city, cafe)
- ‚úÖ **Mood-Based Customization:** Tailor audio to emotional states (relaxing, energetic, focused, peaceful)
- ‚úÖ **AI Music Generation:** Create custom music with control over genre, mood, and instruments
- ‚úÖ **Advanced Audio Analysis:** Analyze audio files to extract insights using Grok's capabilities
- ‚úÖ **Real-Time Adaptation:** Audio environments that adapt to surroundings and context
- ‚úÖ **Immersive 3D Visualization:** Visual representation of audio using Three.js

---

## üìΩÔ∏è Demo & Deliverables

- **Live Demo:** [https://sound-scape-ai-psi.vercel.app/](https://sound-scape-ai-psi.vercel.app/)
- **Demo Video Link:** [Coming Soon]
- **GitHub Repository:** [https://github.com/Sagexd08/SoundScape-Ai](https://github.com/Sagexd08/SoundScape-Ai)

<div align="center">
  <table>
    <tr>
      <td><img src="https://res.cloudinary.com/dporz9gz6/image/upload/v1745176839/WhatsApp_Image_2025-04-21_at_00.38.17_a7bcb060_rarpmc.jpg" alt="Dashboard" width="400"/></td>
      <td><img src="https://res.cloudinary.com/dporz9gz6/image/upload/v1745176839/WhatsApp_Image_2025-04-21_at_00.39.12_a0baa83c_pnmxsk.jpg" alt="AI Studio" width="400"/></td>
    </tr>
    <tr>
      <td align="center"><b>Dashboard</b></td>
      <td align="center"><b>AI Studio</b></td>
    </tr>
  </table>
</div>

---

## ‚úÖ Tasks & Bonus Checklist

- [‚úÖ] **All members of the team completed the mandatory task - Followed at least 2 of our social channels and filled the form**
- [‚úÖ] **All members of the team completed Bonus Task 1 - Sharing of Badges and filled the form (2 points)**
- [‚úÖ] **All members of the team completed Bonus Task 2 - Signing up for Sprint.dev and filled the form (3 points)**

---

## üß™ How to Run the Project

### Requirements:
- Node.js 18.17.0 or later
- npm or yarn
- Supabase account
- OpenAI API key (optional for full functionality)

### Local Setup:
```bash
# Clone the repo
git clone https://github.com/Sagexd08/SoundScape-Ai.git

# Install dependencies
cd SoundScape-Ai/Frontend
npm install --legacy-peer-deps

# Set up environment variables
# Create a .env.local file with the following:
# NEXT_PUBLIC_SUPABASE_URL=your_supabase_url
# NEXT_PUBLIC_SUPABASE_ANON_KEY=your_supabase_anon_key
# NEXT_PUBLIC_OPENAI_API_KEY=your_openai_api_key (optional)

# Start development server
npm run dev
```

Visit `http://localhost:3000` to see the application running locally.

---

## üß¨ Future Scope

<div align="center">
  <img src="https://res.cloudinary.com/dporz9gz6/image/upload/v1745176839/WhatsApp_Image_2025-04-21_at_00.41.17_b0ad1551_d2ku9y.jpg" alt="Future Scope" width="600"/>
</div>

- üìà **Mobile Applications:** Develop native iOS and Android apps for on-the-go audio experiences
- üéß **Hardware Integration:** Connect with smart speakers and headphones for enhanced spatial audio
- üß† **Advanced Biofeedback:** Integrate with wearables to adapt audio based on heart rate, stress levels, and other biometrics
- üåê **Collaborative Environments:** Allow multiple users to share and experience the same audio environment
- ü§ñ **Enhanced AI Models:** Implement more specialized AI models for specific audio genres and use cases
- üîä **Spatial Audio:** Implement 3D audio positioning for truly immersive experiences

---

## üìé Resources / Credits

- [OpenAI](https://openai.com/) for their Text-to-Speech API
- [Supabase](https://supabase.io/) for authentication and database services
- [Vercel](https://vercel.com/) for hosting and deployment
- [shadcn/ui](https://ui.shadcn.com/) for UI components
- [Tailwind CSS](https://tailwindcss.com/) for styling
- [Framer Motion](https://www.framer.com/motion/) for animations
- [Three.js](https://threejs.org/) for 3D graphics
- [Cloudinary](https://cloudinary.com/) for image hosting

---

## üèÅ Final Words

Our hackathon journey with SoundScape AI has been an incredible learning experience. We faced challenges integrating multiple AI models and ensuring they worked harmoniously, but the result is a platform that truly transforms how people experience audio.

We're particularly proud of our multi-AI collaboration approach, which demonstrates how different AI models can complement each other to create something greater than the sum of their parts.

We believe SoundScape AI has the potential to revolutionize various fields, from meditation and wellness to productivity and entertainment, by providing personalized, adaptive audio environments that enhance human experiences.

---

<div align="center">
  <p>Built with ‚ù§Ô∏è by the SoundWave Innovators team</p>
  <p>
    <a href="https://sound-scape-ai-psi.vercel.app/">Live Demo</a> ‚Ä¢
    <a href="https://github.com/Sagexd08/SoundScape-Ai">GitHub</a>
  </p>
</div>
